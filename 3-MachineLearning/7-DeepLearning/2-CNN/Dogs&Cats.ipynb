{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Convolucionales\n",
    "#### Ejemplo clasificación de perros y gatos para CAPTCHA\n",
    "\n",
    "Este notebook utiliza datos de la [competición de Kaggle Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats/overview). En esta competicion se utiliza Asirra (Animal Species Image Recognition for Restricting Access), CAPTCHA que sirve para diferenciar entre una persona o una máquina accediendo a una página web. Este tipo de \"pruebas\" se utilizan para evitar emails de spam, y ataques por fuerza bruta contra servidores.\n",
    "\n",
    "En este notebook vamos a probar que hay técnicas de clasificado automáticas de imágenes mediante redes neuronales, que con las que se intenta saltar CAPTCHA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe76d1d1ded592430e7548feacfa38dc42f085d9"
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "# from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Constants\n",
    "Tendremos una serie de constantes como las dimensiones de las imágenes, que serán fijas a lo largo de todo el notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH=32\n",
    "IMAGE_HEIGHT=32\n",
    "IMAGE_CHANNELS=3\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7335a579cc0268fba5d34d6f7558f33c187eedb3"
   },
   "source": [
    "# Prepare Training Data\n",
    "1. Descárgate el dataset\n",
    "2. Descomprime el dataset y guardalo en la ruta que quieras del ordenador.\n",
    "3. En este punto vamos guardar en una lista las etiquetas de cada foto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = os.getcwd()\n",
    "\n",
    "TRAIN_PATH = ROOT_PATH + \"/data/cat_train/\"\n",
    "TEST_PATH = ROOT_PATH + \"/data/cat_test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"/Users/angelg.villanueva/Documents/04_DATA/041_DATASCIENCE_BOOTCAMP/DS102024_2/3-MachineLearning/7-DeepLearning/2-CNN/data/cat_test\" admiten / si ponemos raw text con r\"\", o bien doblar la barra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "##### CODE #####\n",
    "\n",
    "# Listar todos los archivos de la carpeta de train (TRAIN_PATH)\n",
    "filenames = os.listdir(TRAIN_PATH)\n",
    "\n",
    "# Lista vacia\n",
    "categories = []\n",
    "\n",
    "# Iterar\n",
    "for filename in filenames:\n",
    "    # Saco el nombre\n",
    "    category = filename.split('.')[0]\n",
    "    \n",
    "    # If else\n",
    "    # Guardo en lista\n",
    "    if category == 'dog':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "915bb9ba7063ab4d5c07c542419ae119003a5f98"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dog.8011.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat.5077.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog.7322.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat.2718.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat.10151.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>dog.8008.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>dog.1992.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>dog.12412.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>cat.2701.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>cat.10148.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  category\n",
       "0       dog.8011.jpg         1\n",
       "1       cat.5077.jpg         0\n",
       "2       dog.7322.jpg         1\n",
       "3       cat.2718.jpg         0\n",
       "4      cat.10151.jpg         0\n",
       "...              ...       ...\n",
       "24995   dog.8008.jpg         1\n",
       "24996   dog.1992.jpg         1\n",
       "24997  dog.12412.jpg         1\n",
       "24998   cat.2701.jpg         0\n",
       "24999  cat.10148.jpg         0\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a999484fc35b73373fafe2253ae9db7ff46fdb90"
   },
   "source": [
    "### See Total In count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "fa26f0bc7a6d835a24989790b20f3c6f32946f45"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['category'].value_counts().plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "400a293df3c8499059d9175f3915187074efd971"
   },
   "source": [
    "# See sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m imread\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      4\u001b[0m sample \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(filenames)\n\u001b[1;32m      5\u001b[0m image \u001b[38;5;241m=\u001b[39m imread(TRAIN_PATH \u001b[38;5;241m+\u001b[39m sample)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "from skimage.io import imread\n",
    "import cv2\n",
    "\n",
    "sample = random.choice(filenames)\n",
    "image = imread(TRAIN_PATH + sample)\n",
    "\n",
    "print(image.shape)\n",
    "print(np.max(image))\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una imagen no es mas que un array de HxWxC píxeles, siendo H(Height) y W(Width) las dimensiones de resolución de la imagen, y C el número de canales. Habrá tres valores por píxel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize image\n",
    "Cargar todas las imágenes a la vez es un problema ya que son un total de 25000 (unos 500MB la carpeta de train). Este proceso require mucha memoria, por lo que tendremos que aplicarle un resize a cada imagen para bajarlas de resolución. Esto también nos sirve para solventar el problema de tener imágenes con distintas resoluciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "sample = random.choice(filenames)\n",
    "image = imread(TRAIN_PATH + sample)\n",
    "imagesmall = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "\n",
    "print(\"Tamaño imagen original:\", image.shape)\n",
    "print(\"Tamaño imagen reshape:\", imagesmall.shape)\n",
    "\n",
    "# Original image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "\n",
    "# Resized image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(imagesmall);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color\n",
    "Podríamos cargar las imágenes como blanco y negro, de esta forma se reduciría el espacio de features considerablemente al contar con un único canal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = random.choice(filenames)\n",
    "\n",
    "image = cv2.imread(filename = TRAIN_PATH + sample, flags = cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "print(\"Tamaño imagen original:\", image.shape)\n",
    "plt.imshow(image, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "Llega el momento de cargar los datos. Ya no estan sencillo como cuando teníamos datasets en CSVs puesto que ahora hay que cargar miles de archivos en memoria en este notebook. Para ello necesitaremos un programa iterativo que vaya recorriendo los archivos de la carpeta, cargarlos como array de numpy y almacenarlos en un objeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, im_size):\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    ##### CODE #####\n",
    "    # Iterar sobre todo lo que haya en path\n",
    "    for file in os.listdir(path):\n",
    "        \n",
    "        # Leer la imagen a color y aplicarle el resize\n",
    "        image = imread(path + file)\n",
    "        smallimage = cv2.resize(image, (im_size, im_size))\n",
    "        \n",
    "        # Guardo en X\n",
    "        X.append(smallimage)\n",
    "        \n",
    "        category = file.split('.')[0]\n",
    "        # Miro si es perro y gato para guardar en Y\n",
    "        if category == 'dog':\n",
    "            Y.append(1)\n",
    "        else:\n",
    "            Y.append(0)\n",
    "        \n",
    "\n",
    "    return np.array(X), np.array(Y)\n",
    "    \n",
    "\n",
    "X_train, y_train = read_data(TRAIN_PATH, IMAGE_WIDTH)\n",
    "X_test, y_test = read_data(TEST_PATH, IMAGE_WIDTH)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0].shape)\n",
    "plt.imshow(X_train[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized data\n",
    "Normalizar los datos hará que entrene mucho mejor la red, al estar todos los pixeles en la misma escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Min:\", np.min(X_train))\n",
    "print(\"Max:\", np.max(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "print(\"Min:\", np.min(X_train))\n",
    "print(\"Max:\", np.max(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle data\n",
    "Como hemos cargado los datos de manera ordenada (primero gatos y luego perros), tendremos que desordenarlos para asegurarnos de que no haya ningún sesgo en el entrenamiento ni en la selección de datos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data\n",
    "Podemos guardar los arrays de numpy en un archivo `.npz`, de tal manera que luego sea más rápido importarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(ROOT_PATH + '/data.npz',\n",
    "        X_train = X_train,\n",
    "        y_train = y_train,\n",
    "        X_test = X_test,\n",
    "        y_test = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cargar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(ROOT_PATH + '/data.npz')\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b244e6b7715a04fc6df92dd6dfa3d35c473ca600"
   },
   "source": [
    "# Build Model\n",
    "\n",
    "<img src=\"https://i.imgur.com/ebkMGGu.jpg\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Conv Layer**: extraerá diferentes features de las imagenes\n",
    "* **Pooling Layer**: Reduce las dimensiones de las imágenes tras una capa convolucional\n",
    "* **Fully Connected Layer**: Tras las capas convolucionales, aplanamos las features y las introducimos como entrada de una red neuronal normal.\n",
    "* **Output Layer**: Las predicciones de la red\n",
    "\n",
    "Para el loss y la metrica, se puede usar un binary_crossentropy, al ser un target binario. O "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "layers = [\n",
    "    keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=IMAGE_SIZE),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "]\n",
    "\n",
    "model = keras.Sequential(layers)\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "64*(3*3)*3+ 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "128*(3*3)*3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bd496f6c65888a969be3703135b0b03a8a1190c8"
   },
   "source": [
    "# Callbacks\n",
    "#### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9aa032f0f6da539d23918890d2d131cc3aac8c7a"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "mcheckpoint = ModelCheckpoint(\"callback_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,\n",
    "         y_train,\n",
    "         epochs = EPOCHS,\n",
    "         batch_size = BATCH_SIZE,\n",
    "         callbacks = [earlystop, mcheckpoint],\n",
    "         validation_split = 0.2,\n",
    "         verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "Probemos los datos en el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, model.predict(X_test).round(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_test[-1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test[-1:]).round(0)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'})\n",
    "\n",
    "print(\"Categorias:\", df['category'].unique())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4252cce168ab65f88e44a8ebc2672607bc852af4"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "\n",
    "example_df = df.sample(n=1).reset_index(drop=True)\n",
    "example_df\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 15,\n",
    "    shear_range = 0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1\n",
    ")\n",
    "\n",
    "example_generator = train_datagen.flow_from_dataframe(\n",
    "    example_df,\n",
    "    TRAIN_PATH,\n",
    "    x_col = 'filename',\n",
    "    y_col = 'category',\n",
    "    target_size = (128, 128)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "23d923dba747f8b47dc75569244cecc6f70df321"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i in range(0, 15):\n",
    "    plt.subplot(5, 3, i+1)\n",
    "    for X_batch, Y_batch in example_generator:\n",
    "        image = X_batch[0]\n",
    "        plt.imshow(image)\n",
    "        break\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff760be9104f7d9492467b8d9d3405011aa77d11"
   },
   "source": [
    "# Training Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4eeb7af8dcf02c4ef5ca744c8305c51a2f5cedef"
   },
   "outputs": [],
   "source": [
    "train_df, validate_df = train_test_split(df,\n",
    "                                         test_size=0.20,\n",
    "                                         random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae3dec0361f0443132d0309d3b883ee80070cf9f"
   },
   "outputs": [],
   "source": [
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "\n",
    "print(\"Shape train\", total_train)\n",
    "print(\"Shape validation\", total_validate)\n",
    "validate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4d1c7818703a8a4bac5c036fdea45972aa9e5e9e"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 15,\n",
    "    shear_range = 0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    TRAIN_PATH, \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    class_mode='binary',\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "859c7b2857939c19fd2e3bb32839c9f7deb5aa3f"
   },
   "source": [
    "### Validation Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7925e16bcacc89f4484fb6fe47e54d6420af732e"
   },
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    TRAIN_PATH, \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    class_mode='binary',\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5cd8df64e794ed17de326b613a9819e7da977a0e"
   },
   "source": [
    "# Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0836a4cc8aa0abf603e0f96573c0c4ff383ad56b"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential(layers)\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data = validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####\n",
    "\n",
    "# Listar todos los archivos de la carpeta de train (TEST_PATH)\n",
    "filenames = os.listdir(TEST_PATH)\n",
    "\n",
    "# Lista vacia\n",
    "categories = []\n",
    "\n",
    "# Iterar\n",
    "for filename in filenames:\n",
    "    # Saco el nombre\n",
    "    category = filename.split('.')[0]\n",
    "    \n",
    "    # If else\n",
    "    # Guardo en lista\n",
    "    if category == 'dog':\n",
    "        categories.append('dog')\n",
    "    else:\n",
    "        categories.append('cat')\n",
    "    \n",
    "    \n",
    "test_df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    TEST_PATH, \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    class_mode='binary',\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_generator)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b76c0a9040bc0babf0a453e567e41e22f8a1e0e"
   },
   "source": [
    "# Virtualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79055f2dc3e2abb47bea758e0464c86ca42ab431"
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "ax1.set_xticks(np.arange(1, EPOCHS, 1))\n",
    "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
    "\n",
    "ax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "ax2.set_xticks(np.arange(1, EPOCHS, 1))\n",
    "\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
